# Upload limits / output behavior
MAX_UPLOAD_MB=20
STRICT_LOSSLESS=true
ALLOW_LOSSY_JPEG=true

SKIN_BACKEND=onnx_smp

# Mask / CV processing
MASK_MAX_SIDE=640
MIN_COMPONENT_AREA=256

# Skin detection backend: "onnx_schp" (human parsing), "onnx_segformer24" (human parsing), "onnx_lvmhpv2" (human parsing), "onnx_smp" (default), or "cv"
SKIN_MODEL_PATH=models/skin_smp.onnx
SKIN_SCORE_THRESHOLD=0.5
SKIN_CHANNEL_INDEX=0
SKIN_REQUIRE_MAX=true
SKIN_MARGIN=0.05

# SCHP (human parsing) backend (used when SKIN_BACKEND=onnx_schp)
SCHP_MODEL_PATH=models/schp.onnx
SCHP_INPUT_SIZE=473
# Default assumes LIP label IDs: face=13, leftArm=14, rightArm=15, leftLeg=16, rightLeg=17
SCHP_SKIN_CLASS_IDS=13,14,15,16,17
# Default assumes LIP label IDs: hair=2
SCHP_HAIR_CLASS_IDS=2
SCHP_MIN_CONFIDENCE=0.0

# SegFormer Human Parse 24 backend (used when SKIN_BACKEND=onnx_segformer24)
SEGFORMER24_MODEL_PATH=models/model.onnx
SEGFORMER24_INPUT_SIZE=512
SEGFORMER24_SKIN_CLASS_IDS=11,14,15,16,17,18
SEGFORMER24_HAIR_CLASS_IDS=2
SEGFORMER24_FACE_CLASS_IDS=14
SEGFORMER24_NECK_FROM_FACE=true
SEGFORMER24_NECK_EXTEND_FRAC=0.35
SEGFORMER24_NECK_EXPAND_X_FRAC=0.10
SEGFORMER24_MIN_CONFIDENCE=0.0

# LV-MHP v2 human parsing backend (used when SKIN_BACKEND=onnx_lvmhpv2)
# You must provide the ONNX model and set the label IDs for the LV-MHP v2 label set.
LVMHP_MODEL_PATH=models/lvmhp_v2.onnx
LVMHP_INPUT_SIZE=512
# If your ONNX model has multiple outputs, set this to force-select the output index that contains the semantic parsing map.
# Use -1 to auto-select.
LVMHP_OUTPUT_INDEX=-1
# Class-id offset applied before matching against model outputs (use -1 if your config uses background-included IDs but the model outputs 58 classes without background).
LVMHP_CLASS_ID_OFFSET=0
# Preprocess: rgb_imagenet (common) or schp_bgr_imagenet (SCHP-style exports)
LVMHP_PREPROCESS=rgb_imagenet
# MHParsNet-style decoding knobs (used when the model outputs kernels+mask features rather than per-pixel logits).
LVMHP_CATE_THRESHOLD=0.35
LVMHP_MASK_THRESHOLD=0.5
LVMHP_MAX_INSTANCES=200
# Comma-separated label IDs.
# For MHParsNet trained on MHPv2, the dataset uses 0=background and the following part IDs:
# - Hair=4, Face=3, Left/Right arms=5,6, Left/Right hands=7,8, Torso-skin=16, Left/Right legs=30,31, Left/Right feet=32,33
# If your ONNX export outputs 58 classes WITHOUT a background class, subtract 1 from all IDs below.
LVMHP_SKIN_CLASS_IDS=3,5,6,7,8,16,30,31,32,33
LVMHP_HAIR_CLASS_IDS=4
LVMHP_FACE_CLASS_IDS=3
LVMHP_NECK_FROM_FACE=true
LVMHP_NECK_EXTEND_FRAC=0.35
LVMHP_NECK_EXPAND_X_FRAC=0.10
LVMHP_MIN_CONFIDENCE=0.0

# Optional: fuse masks from two backends (recommended when neither is perfect alone)
# Example:
#   MASK_FUSION_MODE=overlap_filter
#   MASK_FUSION_BACKENDS=onnx_schp,onnx_segformer24
MASK_FUSION_MODE=none
MASK_FUSION_BACKENDS=
MASK_FUSION_BINARIZE_THRESHOLD=0.5
MASK_FUSION_OVERLAP_DILATE_PX=3
MASK_FUSION_MIN_OVERLAP_PIXELS=25
MASK_FUSION_MIN_OVERLAP_FRAC=0.0
MASK_FUSION_MIN_COMPONENT_AREA=256

# Optional: also censor hair (supported with onnx_smp, onnx_schp, onnx_segformer24 backends)
CENSOR_HAIR=true
HAIR_SCORE_THRESHOLD=0.5
HAIR_CHANNEL_INDEX=2
HAIR_REQUIRE_MAX=true
HAIR_MARGIN=0.05
HAIR_MIN_COMPONENT_AREA=128

# CV fallback knobs (used only when SKIN_BACKEND=cv)
# SKIN_MODE can be: "auto" | "adaptive" | "heuristic"
SKIN_MODE=auto
SKIN_MAHA_THRESHOLD=3.5
SKIN_MIN_SEED_PIXELS=350
