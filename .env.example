# Upload limits / output behavior
MAX_UPLOAD_MB=20
STRICT_LOSSLESS=true
ALLOW_LOSSY_JPEG=true

SKIN_BACKEND=onnx_mhp

# Mask / CV processing
MASK_MAX_SIDE=640
MIN_COMPONENT_AREA=256

# Skin detection backend: "onnx_mhp" (LV-MHP v2), "onnx_schp" (human parsing), "onnx_smp", or "cv"
SKIN_MODEL_PATH=models/skin_smp.onnx
SKIN_SCORE_THRESHOLD=0.5
SKIN_CHANNEL_INDEX=0
SKIN_REQUIRE_MAX=true
SKIN_MARGIN=0.05

# LV-MHP v2 / MHParsNet backend (used when SKIN_BACKEND=onnx_mhp)
MHP_MODEL_PATH=models/MHParsNet_logits.onnx
MHP_INPUT_SIZE=512
# LV-MHP v2 59-class IDs (example: face/arms/hands/torso_skin/legs/feet)
MHP_SKIN_CLASS_IDS=3,16,5,6,7,8,30,31
MHP_MIN_CONFIDENCE=0.0
# ONNX I/O names (as exported)
MHP_INPUT_NAME=image
MHP_OUTPUT_NAME=logits
# Preprocessing (depends on how you exported ONNX)
MHP_INPUT_BGR=false
# Normalization (applied to float32 pixels in 0..255, RGB order by default)
MHP_NORM_MEAN=123.675,116.28,103.53
MHP_NORM_STD=58.395,57.12,57.375

# SCHP (human parsing) backend (used when SKIN_BACKEND=onnx_schp)
SCHP_MODEL_PATH=models/schp.onnx
SCHP_INPUT_SIZE=473
# Default assumes LIP label IDs: face=13, leftArm=14, rightArm=15, leftLeg=16, rightLeg=17
SCHP_SKIN_CLASS_IDS=13,14,15,16,17
SCHP_MIN_CONFIDENCE=0.0

# Optional: also censor hair (only supported with the onnx_smp backend)
CENSOR_HAIR=true
HAIR_SCORE_THRESHOLD=0.5
HAIR_CHANNEL_INDEX=2
HAIR_REQUIRE_MAX=true
HAIR_MARGIN=0.05
HAIR_MIN_COMPONENT_AREA=128

# CV fallback knobs (used only when SKIN_BACKEND=cv)
# SKIN_MODE can be: "auto" | "adaptive" | "heuristic"
SKIN_MODE=auto
SKIN_MAHA_THRESHOLD=3.5
SKIN_MIN_SEED_PIXELS=350
